## Technical Supplement A. Gini Statistic {-}

### TS A.1. The Classic Lorenz Curve {-}

In welfare economics, it is common to compare distributions via the **Lorenz curve**, developed by Max Otto Lorenz [@lorenz1905methods]. A Lorenz curve is a graph of the proportion of a population on the horizontal axis and a distribution function of interest on the vertical axis. It is typically used to represent income distributions. When the income distribution is perfectly aligned with the population distribution, the Lorenz curve results in a 45 degree line that is known as the *line of equality*. The area between the Lorenz curve and the line of equality is a measure of the discrepancy between the income and population distributions. Two times this area is known as the **Gini index**, introduced by Corrado Gini in 1912. 


```{r echo=FALSE}  
# Lorenz Curve
##time1<-Sys.time()
set.seed(2017) #set seed to reproduce work 
nTot<-2000  #number of simulations
alpha<-2
theta<-100
Losses<-rgamma(nTot,alpha,scale = theta)  
y <- Losses[order(Losses)]
DFLosses = cumsum(y)/sum(y)
DFLine <- (1:nTot)/nTot
Gini = 2*(sum(rank(y)*y)/sum(y) - (nTot+1)/2)/nTot

```

**Example -- Classic Lorenz Curve.** For an insurance example, Figure \@ref(fig:ClassicLorenz) shows a distribution of insurance losses. This figure is based on a random sample of `r nTot` losses. The left-hand panel shows a right-skewed histogram of losses.  The right-hand panel provides the corresponding Lorenz curve, showing again a skewed distribution. For example, the arrow marks the point where 60 percent of the policyholders have 30 percent of losses. The 45 degree line is the line of equality; if each policyholder has the same loss, then the loss distribution would be at this line. The Gini index, twice the area between the Lorenz curve and the 45 degree line, is `r round(Gini*100,1)` percent for this data set.

```{r, ClassicLorenz, fig.cap='Distribution of insurance losses.', out.width='90%', fig.asp=0.5, fig.align='center', echo=FALSE}
par(mfrow=c(1,2))
plot(density(Losses), main="", xlab="Losses")
plot(DFLine,DFLosses, cex=0.25, xlab="Proportion of Observations", ylab="Proportion of Losses")
abline(0,1)
arrows(0.8, 0.2, 0.6, 0.3,length=0.1, angle = 30)
text(.85, .35, "(0.60, 0.30)", cex=.8)

```

### TS A.2. Ordered Lorenz Curve and the Gini Index {-}
We now introduce a modification of the classic Lorenz curve and Gini statistic that is useful in insurance applications. Specifically, we introduce an *ordered* Lorenz curve which is a graph of the distribution of losses versus premiums, where both losses and premiums are ordered by relativities. Intuitively, the relativities point towards aspects of the comparison where there is a mismatch between losses and premiums. To make the ideas concrete, we first provide some notation. We will consider $i=1, \ldots, n$ policies. For the $i$th policy, let

* $y_i$ denote the insurance loss,
* $\mathbf{x}_i$ be the set of policyholder characteristics known to the analyst,
* $P_i=P(\mathbf{x}_i)$ be the associated premium that is a function of $\mathbf{x}_i$,
* $S_i = S(\mathbf{x}_i)$ be an insurance score under consideration for rate changes, and
* $R_i = R(\mathbf{x}_i)=S(\mathbf{x}_i)/P(\mathbf{x}_i)$ is the relativity, or relative premium.

Thus, the set of information used to calculate the ordered Lorenz curve for the $i$th policy is $(y_i, P_i, S_i, R_i)$.

#### Ordered Lorenz Curve {-}

We now sort the set of policies based on relativities (from smallest to largest) and compute the premium and loss distributions. Using notation, the premium distribution is
\begin{equation}
\hat{F}_P(s) =  \frac{ \sum_{i=1}^n
P(\mathbf{x}_i) \mathrm{I}(R_i \leq s) }{\sum_{i=1}^n P(\mathbf{x}_i)} ,(\#eq:EmpPremDF)
\end{equation}
and the loss distribution is
\begin{equation}
\hat{F}_{L}(s) =  \frac{ \sum_{i=1}^n y_i \mathrm{I}(R_i
\leq s) }{\sum_{i=1}^n y_i} ,(\#eq:EmpLossDF)
\end{equation}
where $\mathrm{I}(\cdot)$ is the indicator function, returning a 1 if the event is true and zero otherwise. The graph $\left(\hat{F}_P(s),\hat{F}_{L}(s) \right)$ is an **ordered Lorenz curve**.

The classic Lorenz curve shows the proportion of policyholders on the horizontal axis and the loss distribution function on the vertical axis. The ordered Lorenz curve extends the classical Lorenz curve in two ways, (1) through the ordering of risks and prices by relativities and (2) by allowing prices to vary by observation. We summarize the ordered Lorenz curve in the same way as the classic Lorenz curve using a Gini index, defined as twice the area between the curve and a 45 degree line. The analyst seeks ordered Lorenz curves that approach passing through the southeast corner (1,0); these have greater separation between the loss and premium distributions and therefore larger Gini indices.

**Example -- Loss Distribution.**

Suppose we have $n=5$ policyholders with experience as:


Variable      $i$                1   2   3  4  5  Sum
----------   -----------------   -   -   -  -  -  ---
Loss         $y_i$               5   5   5  4  6   25
Premium      $P(\mathbf{x}_i)$   4   2   6  5  8   25
Relativity   $R(\mathbf{x}_i)$   5   4   3  2  1 
----------   -----------------   -   -   -  -  -  ---


Determine the Lorenz curve and the ordered Lorenz curve.

<h5 style="text-align: center;"><a id="displayLorenz.1" href="javascript:toggleEX('toggleLorenz','displayLorenz.1');"><i><strong>Show Example Solution</strong></i></a> </h5><div id="toggleLorenz" style="display: none">

***

```{r, LorenzVsOrdered, fig.cap='Lorenz versus Ordered Lorenz Curve', out.width='90%', fig.asp=0.5, fig.align='center', echo=FALSE}
# EXAMPLE
x = c(4,2,6,5,8)
y = c(5,5,5,4,6)
R = c(5,4,3,2,1)/3
n1 = length(x)
XYmat = data.frame(cbind(x,y,R))
XYmatYOrder = XYmat[order(y),]  #  Sort by y's
origorder = (1:n1)
DFy1 = c(0,cumsum(XYmatYOrder$y)/sum(y))
DFx1 = c(0,origorder/n1) 
XYmatROrder = XYmat[order(R),]  #  Sort by relativities R's
DFy4 = c(0,cumsum(XYmatROrder$y)/sum(y))
DFx4 = c(0,cumsum(XYmatROrder$x)/sum(x))

#  FIGURE 3
par(mfrow=c(1, 2))
#  Lorenz Curve
plot(DFx1,DFy1,xlim=c(0,1),ylim=c(0,1), type="b",
xlab="People Distn",ylab="", main="Lorenz");abline(0,1)
mtext("Loss Distn", side=2, line=-0.5, at=1.1,   las=1, cex=1.0)
#  Ordered Lorenz Curve
plot(DFx4,DFy4,xlim=c(0,1),ylim=c(0,1), type="b",
xlab="Premium Distn",ylab="", main="Ordered Lorenz");abline(0,1)
mtext("Loss Distn", side=2, line=-0.5, at=1.1,   las=1, cex=1.0)
```

Figure \@ref(fig:LorenzVsOrdered) compares the Lorenz curve to the ordered version based on this data. The left-hand panel shows the Lorenz curve. The horizontal axis is the cumulative proportion of policyholders (0, 0.2, 0.4, and so forth) and the vertical axis is the cumulative proportion of losses (0, 4/25, 9/25, and so forth). This figure shows little separation between the distributions of losses and policyholders.

The right-hand panel shows the ordered Lorenz curve. Because observations are sorted by relativities, the first point after the origin (reading from left to right) is (8/25, 6/25). The second
point is (13/25, 10/25), with the pattern continuing. For the ordered Lorenz curve, the horizontal axis uses premium weights, the vertical axis uses loss weights, and both axes are ordered by relativities. From the figure, we see that there is greater separation between losses and premiums when viewed through this relativity.

***

</div>

#### Gini Index {-}

Specifically, the Gini index can be calculated as follows. Suppose that the empirical ordered Lorenz curve is given by $\{ (a_0=0, b_0=0), (a_1, b_1), \ldots,$ $(a_n=1, b_n=1) \}$ for a sample of $n$ observations. Here, we use $a_j = \hat{F}_P(R_j)$ and $b_j = \hat{F}_{L}(R_j)$. Then, the empirical Gini index is
\begin{eqnarray}
\widehat{Gini} &=&  2\sum_{j=0}^{n-1} (a_{j+1} - a_j) \left \{
\frac{a_{j+1}+a_j}{2} - \frac{b_{j+1}+b_j}{2} \right\} \nonumber \\
&=& 1 - \sum_{j=0}^{n-1} (a_{j+1} - a_j) (b_{j+1}+b_j) .(\#eq:GiniDefn)
\end{eqnarray}

**Example -- Loss Distribution: Continued.** In the figure, the Gini index for the left-hand panel is 5.6\%. In contrast, the Gini index for the right-hand panel is 14.9\%.  $~~\Box$


### TS A.3. Out-of-Sample Validation {-}

The Gini statistics based on an ordered Lorenz curve can be used for out-of-sample validation. The procedure follows:

1.  Use an in-sample data set to estimate several competing models.
2.  Designate an out-of-sample, or validation, data set of the form $\{(y_i, \mathbf{x}_i), i=1,\ldots,n\}$.
3.  Establish one of the models as the base model. Use this estimated model and explanatory variables from the validation sample to form premiums of the form $P(\mathbf{x}_i)$.
4.  Pick one of the competing models. Use this estimated model and explanatory variables from the validation sample to form scores of the form $S(\mathbf{x}_i)$.
5.  From the premiums and scores, develop relativities $R_i =S(\mathbf{x}_i)/P(\mathbf{x}_i)$.
6.  Use the validation sample outcomes $y_i$ to compute the Gini statistic.

**Example -- Out-of-Sample Validation**

```{r, warning=FALSE, message=FALSE, echo=FALSE} 
set.seed(2017)
NInsamp  = 500
NOutsamp = 200
Nstate   = 25
InClaims   <- matrix(0,NInsamp,Nstate)
OutClaims  <- matrix(0,NOutsamp,Nstate)
PredClaims <- matrix(0,NOutsamp,Nstate)
 for (iState in  1:Nstate) { 
InClaims[,iState]   <- rgamma(NInsamp, shape = 5, scale = 18+iState*2)
PredClaims[,iState] <- rep(mean(InClaims[,iState]),NOutsamp)
OutClaims[,iState]  <- rgamma(NOutsamp, shape = 5, scale = 18+iState*2)
 }
#C;PredClaims;OutClaims
Predvec  <- as.vector(PredClaims)
Flatpred <- Predvec*0+1
Outy     <- as.vector(OutClaims)
```

Suppose that we have experience from `r Nstate` states and that, for each state, we have available `r NInsamp` observations that can be used to predict future losses. For simplicity, assume that the analyst knows that these losses were generated by a gamma distribution with a common shape parameter equal to 5. Unknown to the analyst, the scale parameters vary by state, from a low of 20 to `r 18+2*(Nstate-1)`. To compute base premiums, the analyst assumes a scale parameter that is common to all states that is to be estimated from the data. As an alternative, the analyst allows the scale parameters to vary by state and will again use the data to estimate these parameters.

An out of sample validation set of `r NOutsamp` from each state is available. Determine the ordered Lorenz curve and the corresponding Gini statistic to compare the two rate procedures.

<h5 style="text-align: center;"><a id="displayLorenzeExample" href="javascript:toggleEX('toggleExampleLor','displayLorenzeExample');"><i><strong>Show Example Solution</strong></i></a> </h5><div id="toggleExampleLor" style="display: none">

***


Recall for the gamma distribution that the mean equals the shape times the scale or, 5 times the scale parameter, for our example. So, you can check that the maximum likelihood estimates are simple the average experience.

For our base premium, we assume a common distribution among all states. For these simulated data, the average is **P**=`r round(mean(InClaims),digits=2)`. You can think of this common premium as based on a *community rating* principle. 

As an alternative, we use averages that are state-specific; these averages form our scores **S**. Because this illustration uses means that vary by states, we anticipate this alternative rating procedure to be preferred to the community rating procedure. 

Out of sample claims were generated from the same gamma distribution, with `r NOutsamp` observations for each state. The following `R` code shows how to calculate the ordered Lorenz curve.


<h5 style="text-align: center;"><a id="displayGiniCode.4" href="javascript:togglecode('toggleGiniCode.4','displayGiniCode.4');"><i><strong>Show R Code</strong></i></a> </h5>
<div id="toggleGiniCode.4" style="display: none">

```{r echo=TRUE} 
GiniCalc <- function(Claims,PIx,Sx){
   y   <- Claims/mean(Claims)
   PIx <- PIx/mean(PIx)
   Sx  <- Sx/mean(Sx)
   Rx  <- Sx/PIx       #Relativity
   n   <- length(PIx)
   origorder <- (1:n)
   PSRmat <- data.frame(cbind(PIx,Sx,Rx,y,origorder))
   PSRmatOrder <- PSRmat[order(Rx),]  #  Sort by relativity
#  PREMIUM, LOSS DFs
   DFPrem <- cumsum(PSRmatOrder$PIx)/n
   DFLoss <- cumsum(PSRmatOrder$y)/n
#  GINI CALC
   DFPremdiff <- DFPrem[2:n]-DFPrem[1:(n-1)]
   DFPremavg  <- (DFPrem[2:n]+DFPrem[1:(n-1)])/2
   DFLossavg  <- (DFLoss[2:n]+DFLoss[1:(n-1)])/2
   (Gini <- 2*crossprod(DFPremdiff,DFPremavg-DFLossavg)) 
#  STANDARD ERROR CALC
   h1 <- 0.5* (PSRmatOrder$PIx*DFLoss + PSRmatOrder$y*(1-DFPrem) ) #  PROJECTION CALC
   h1bar   <- mean(h1) 
   sigmah  <- var(h1)
   sigmahy <- cov(h1,PSRmatOrder$y)
   sigmahpi <- cov(h1,PSRmatOrder$PIx)
   sigmay  <- var(y)
   sigmapi <- var(PIx)
   sigmaypi <- cov(PSRmatOrder$y,PSRmatOrder$PIx)
   temp1= 4*sigmah + h1bar^2*sigmay + h1bar^2*sigmapi -
           4*h1bar*sigmahy - 4*h1bar*sigmahpi +
           2*h1bar^2*sigmaypi
   sigmaGini  <- 4*temp1
   stderrGini <- sqrt(sigmaGini/n) 
   check <- var(PIx-Sx)
   Gini  <- Gini*(check != 0)
   stderrGini <- stderrGini*(check != 0)
   Retmat <- data.frame(cbind(DFPrem,DFLoss)) 
   RetmatGini<-list(Retmat,Gini,stderrGini)
     return(RetmatGini)
}
temp=GiniCalc(Claims=Outy,PIx=Flatpred,Sx=Predvec)
Results=temp[[1]]
Gini <- temp[[2]];#Gini
stderrorGini <- temp[[3]];#Standard Error

```

</div>

```{r, fig.cap='', out.width='50%', fig.asp=1, fig.align='center', echo=FALSE} 
plot(Results[,1],Results[,2], xlab="", ylab="",type="l",cex = 0.3)
abline(0,1)
mtext("Loss Distn", side=2, line=-1.4, at=1.1,   las=1, cex=1.2)
mtext("Premium Distn", side=1, line=2.2, at=0.5,   las=1, cex=1.2)
text(0.4, 0.6, "Line of Equality", cex=1)
text(0.7, 0.3, "Ordered Lorenz Curve", cex=1)
```

For these data, the Gini index is `r round(Gini,digits=3)` with a standard error equal to `r round(stderrorGini,digit=5)`. This suggests that the state-specific alternative procedure is strongly preferred to the base community rating procedure.

***

</div>

#### Discussion {-}

In insurance claims modeling, standard out-of-sample validation measures are not the most informative due to the high proportions of zeros (corresponding
to no claim) and the skewed fat-tailed distribution of the positive values. In contrast, the Gini index works well with many zeros (see the demonstration in [@frees2014insurance]). Moreover, the Gini index can be motivated by the economics of insurance. Intuitively, the Gini index measures the negative covariance between a policy's "profit" ($P-y$, premium minus loss) and the rank of the relativity (**R**, score divided by premium). That is, the close approximation

$$\widehat{Gini} \approx - \frac{2}{n} \widehat{Cov} \left\{ (P-y), rank(R) \right\} .$$

This observation leads an insurer to seek a score and resulting relativity that produces to a large Gini index. In this way, the Gini index and associated ordered Lorenz curve are useful for identifying profitable blocks of insurance business.

Unlike classical measures of association, the Gini index assumes that a premium base **P** is currently in place and seeks to assess vulnerabilities of this structure. This approach is more akin to hypothesis testing (when compared to goodness of fit) where one identifies a "null hypothesis" as the current state of the world and uses decision-making criteria/statistics to compare this with an "alternative hypothesis."

Properties of the insurance version of the Gini statistic were developed by [@frees2011summarizing] and [@frees2014insurance]. In these articles you can find formulas for the standard errors and other additional background information.

